{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ppdire.py` subpackage: examples\n",
    "================================\n",
    "Here, we will illustrate how to use `ppdire.py` to perform different types of projection pursuit dimension reduction. \n",
    "\n",
    "To run a toy example, start by sourcing packages and data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "import pandas as ps\n",
    "import numpy as np\n",
    "data = ps.read_csv(\"../data/Returns_shares.csv\")\n",
    "\n",
    "columns = data.columns[2:8]\n",
    "(n,p) = data.shape\n",
    "datav = np.matrix(data.values[:,2:8].astype('float64'))\n",
    "y = datav[:,0]\n",
    "X = datav[:,1:5]\n",
    "        \n",
    "# Scale data\n",
    "from direpack import VersatileScaler\n",
    "centring = VersatileScaler()\n",
    "Xs = centring.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. Comparison of PP estimates to Scikit-Learn \n",
    "======================================\n",
    "Let us at first run `ppdire` to produce slow, approximate PP estimates of \n",
    "PCA and PLS. This makes it easy to verify that the algorithm is correct. \n",
    "        \n",
    "1\\.1\\. PCA\n",
    "--------------\n",
    "By setting the projection index to variance, projection pursuit is a slow, approximate way to calculate PCA. Let's compare the `ppdire` results to `sklearn`'s.\n",
    "\n",
    "- PCA ex `scikit-learn` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.decomposition as skd\n",
    "skpca = skd.PCA(n_components=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.94 ms, sys: 1.27 ms, total: 3.21 ms\n",
      "Wall time: 8.02 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.6160923 ,  0.09574799, -0.27553202,  0.73167254],\n",
       "       [ 0.3612025 ,  0.79963754,  0.40566716, -0.25602091],\n",
       "       [ 0.57369773, -0.2220554 , -0.47175995, -0.63166832],\n",
       "       [ 0.40104108, -0.54963945,  0.73277473,  0.01018414]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time skpca.fit(Xs)\n",
    "skpca.components_.T # sklearn outputs loadings as rows ! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- PCA ex `ppdire`, using SLSQP optimization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from direpack import dicomo, ppdire\n",
    "pppca = ppdire(projection_index = dicomo, pi_arguments = {'mode' : 'var'}, n_components=4, optimizer='SLSQP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 208 ms, sys: 18.1 ms, total: 227 ms\n",
      "Wall time: 143 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.61607418,  0.09583099,  0.27564666, -0.73163593],\n",
       "       [-0.36117418,  0.79968851, -0.40559672,  0.25604181],\n",
       "       [-0.57366555, -0.22197832,  0.47186547,  0.63170265],\n",
       "       [-0.40114045, -0.54958196, -0.73270266, -0.01015964]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time pppca.fit(X)\n",
    "pppca.x_loadings_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- PCA ex `ppdire`, using its native `grid` algorithm optimization \\[1\\]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pppca = ppdire(projection_index = dicomo, pi_arguments = {'mode' : 'var'}, n_components=4, optimizer='grid',optimizer_options={'ndir':1000,'maxiter':1000})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "1\n",
      "2\n",
      "CPU times: user 38.5 s, sys: 1.4 s, total: 39.9 s\n",
      "Wall time: 37.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.61598274, -0.09421448, -0.27613309,  0.73205157],\n",
       "       [ 0.36137778, -0.80127483,  0.40173098, -0.25522632],\n",
       "       [ 0.57377558,  0.22404487, -0.47051245, -0.63154901],\n",
       "       [ 0.40094043,  0.54670882,  0.73551452,  0.01041449]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time pppca.fit(X)\n",
    "pppca.x_loadings_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\.2\\. PLS \n",
    "----------\n",
    "Likewise, by setting the projection index to covariance, one obtains partial least squares. \n",
    "\n",
    "- PLS ex `scikit-learn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.cross_decomposition as skc\n",
    "skpls = skc.PLSRegression(n_components=4)\n",
    "skpls.fit(Xs,(y-np.mean(y))/np.std(y))\n",
    "skpls.x_scores_\n",
    "print(skpls.coef_) \n",
    "Xs*skpls.coef_*np.std(y) + np.mean(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- PLS ex `ppdire`, using SLSQP optimization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pppls = ppdire(projection_index = dicomo, pi_arguments = {'mode' : 'cov'}, n_components=4, square_pi=True, optimizer='SLSQP', optimizer_options={'maxiter':500})\n",
    "pppls.fit(X,y)\n",
    "pppls.x_scores_\n",
    "print(pppls.coef_scaled_) # Column 4 should agree with skpls.coef_\n",
    "pppls.fitted_  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- PLS ex `ppdire`, `grid` optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pppls = ppdire(projection_index = dicomo, pi_arguments = {'mode' : 'cov'}, n_components=4, square_pi=True, optimizer='grid',optimizer_options={'ndir':1000,'maxiter':1000})\n",
    "pppls.fit(X,y)\n",
    "pppls.x_scores_\n",
    "print(pppls.coef_scaled_) # Column 4 should agree with skpls.coef_\n",
    "pppls.fitted_  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remark: Dimension Reduction techniques based on projection onto latent variables, \n",
    "such as PCA, PLS and ICA, are sign indeterminate with respect to the components. \n",
    "Therefore, signs of estimates by different algorithms can be opposed, yet the \n",
    "absolute values should be identical up to algorithm precision.  Here, this implies\n",
    "that `sklearn` and `ppdire`'s `x_scores_` and `x_loadings` can have opposed signs,\n",
    "yet the coefficients and fitted responses should be identical. \n",
    "\n",
    "2\\. Robust projection pursuit estimators\n",
    "=================================\n",
    "\n",
    "Note that optimization through `scipy.optimize` is much more efficient than the native `grid` algorithm, yet will only provide correct results for classical projection indices. The native `grid` algorithm should be used when \n",
    "the projection index involves order statistics of any kind, such as ranks, trimming, winsorizing, or empirical quantiles.\n",
    "\n",
    "- Robust PCA based on the Median Absolute Deviation (MAD) \\[2\\]. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lcpca = ppdire(projection_index = dicomo, pi_arguments = {'mode' : 'var', 'center': 'median'}, n_components=4, optimizer='grid',optimizer_options={'ndir':1000,'maxiter':10})\n",
    "#set a higher maxiter for convergence and precision! \n",
    "lcpca.fit(X)\n",
    "lcpca.x_loadings_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To extend to Robust PCR, just add `y`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " lcpca.fit(X,y,regopt='robust')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Robust Continuum Regression \\[4\\] based on trimmed continuum association: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcr = ppdire(projection_index = dicomo, pi_arguments = {'mode' : 'continuum'}, n_components=4, trimming=.1, alpha=.5, optimizer='grid',optimizer_options={'ndir':250,'maxiter':1000})\n",
    "rcr.fit(X,y=y,regopt='robust')\n",
    "rcr.x_loadings_\n",
    "rcr.x_scores_\n",
    "rcr.coef_scaled_\n",
    "rcr.predict(X[:2666])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now plot the results. The `plot` subpackage contains a plotting function for `ppdire`. To plot predicted vs. actual values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from direpack import ppdire_plot\n",
    "dr_plot=ppdire_plot(rcr,['w','w','g','y','m','b','k'])\n",
    "dr_plot.plot_yyp(label='KMB',title='fitted vs true quotation, training set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dr_plot.plot_yyp(ytruev=y[2666:],Xn=X[2666:],label='KMB',title='fitted vs true quotation, test set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To plot scores: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dr_plot.plot_projections(Xn=X[2666:],label='KMB',title='fitted vs true quotation, test set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. Projection pursuit generalized betas\n",
    "================================\n",
    "\n",
    "Generalized betas are obtained as the projection pursuit weights using the \n",
    "co-moment analysis projection index (CAPI) \\[2\\]. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ppdire import capi \n",
    "est = ppdire(projection_index = capi, pi_arguments = {'max_degree' : 3,'projection_index': dicomo, 'scaling': False}, n_components=1, trimming=0,center_data=True,scale_data=True)\n",
    "est.fit(X,y=y,ndir=200)\n",
    "est.x_weights_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that these data aren't the greatest illustration. Evaluating CAPI projections, makes more sense if y is a market index, e.g. SPX. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. Cross-validating through `scikit-learn` \n",
    "===========================================\n",
    "\n",
    "The `ppdire` class is 100% compatible with `scikit-learn`, which allows, for instance, hyperparameter tuning through `GridSearchCV`. \n",
    "To try out, uncomment the line below and run. (this may take some time). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to try out:\n",
    "\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# rcr_cv = GridSearchCV(ppdire(projection_index=dicomo, \n",
    "#                                    pi_arguments = {'mode' : 'continuum'\n",
    "#                                                    }, \n",
    "#                                    optimizer = 'grid',\n",
    "#                                   optimizer_options = {'ndir':1000,'maxiter':1000}\n",
    "#                                   ), \n",
    "#                             cv=10, \n",
    "#                             param_grid={\"n_components\": [1, 2, 3], \n",
    "#                                         \"alpha\": np.arange(.1,3,.3).tolist(),\n",
    "#                                         \"trimming\": [0, .15]\n",
    "#                                        }\n",
    "#                            )\n",
    "#       rcr_cv.fit(X[:2666],y[:2666]) \n",
    "#       rcr_cv.best_params_\n",
    "#       rcr_cv.predict(X[2666:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. Data compression\n",
    "=================\n",
    "While `ppdire` is very flexible and can project according to a very wide variety \n",
    "of projection indices, it can be computationally demanding. For flat data tables,\n",
    "a workaround has been built in. However, not that running the code in the next field can take quite some time nonetheless.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load flat data \n",
    "datan = ps.read_csv(\"../data/Glass_df.csv\")\n",
    "X = datan.values[:,100:300]\n",
    "y = datan.values[:,2]\n",
    "        \n",
    "# Now compare\n",
    "rcr = ppdire(projection_index = dicomo, \n",
    "                    pi_arguments = {'mode' : 'continuum'}, \n",
    "                    n_components=4, \n",
    "                    trimming=.1, \n",
    "                    alpha=.5, \n",
    "                    compression = False, \n",
    "                    optimizer='grid',\n",
    "                    optimizer_options={'ndir':1000,'maxiter':1000})\n",
    "rcr.fit(X,y)\n",
    "print(rcr.coef_)\n",
    "        \n",
    "rcr = ppdire(projection_index = dicomo, \n",
    "                    pi_arguments = {'mode' : 'continuum'}, \n",
    "                    n_components=4, \n",
    "                    trimming=.1, \n",
    "                    alpha=.5, \n",
    "                    compression = True, \n",
    "                    optimizer='grid',\n",
    "                    optimizer_options={'ndir':1000,'maxiter':1000})\n",
    "rcr.fit(X,y)\n",
    "rcr.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, compression will not work properly if the data contain several low scale \n",
    "varables. In this example, it will not work for `X = datan.values[:,8:751]`. This \n",
    "will throw a warning, and `ppdire` will continue without compression. \n",
    "\n",
    "References\n",
    "----------------\n",
    "1. [Robust Multivariate Methods: The Projection Pursuit Approach](https://link.springer.com/chapter/10.1007/3-540-31314-1_32), Peter Filzmoser, Sven Serneels, Christophe Croux and Pierre J. Van Espen, in: From Data and Information Analysis to Knowledge Engineering, Spiliopoulou, M., Kruse, R., Borgelt, C., Nuernberger, A. and Gaul, W., eds., Springer Verlag, Berlin, Germany, 2006, pages 270--277.\n",
    "2. [Projection pursuit based generalized betas accounting for higher order co-moment effects in financial market analysis](https://arxiv.org/pdf/1908.00141.pdf), Sven Serneels, in: JSM Proceedings, Business and Economic Statistics Section. Alexandria, VA: American Statistical Association, 2019, 3009-3035.\n",
    "3. Robust principal components and dispersion matrices via projection pursuit, Chen, Z. and Li, G., Research Report, Department of Statistics, Harvard University, 1981.\n",
    "4. [Robust Continuum Regression](https://www.sciencedirect.com/science/article/abs/pii/S0169743904002667), Sven Serneels, Peter Filzmoser, Christophe Croux, Pierre J. Van Espen, Chemometrics and Intelligent Laboratory Systems, 76 (2005), 197-204."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "pp-conda",
   "language": "python",
   "name": "pp-conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
